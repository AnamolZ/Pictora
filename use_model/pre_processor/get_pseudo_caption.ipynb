{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "model_detection = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_detection.to(device)\n",
    "model_detection.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag',\n",
    "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop',\n",
    "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "image_paths = glob.glob(os.path.join(\"dataset\", \"*.jpg\"))[30000:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-large\",\n",
    "    device=0 if gpu_available else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "with tqdm(total=len(image_paths), desc=\"Processing Images\", unit=\"img\") as pbar:\n",
    "    for image_path in image_paths:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img).to(device)\n",
    "        with torch.no_grad():\n",
    "            prediction = model_detection([img_tensor])\n",
    "        scores = prediction[0]['scores'].cpu().numpy()\n",
    "        labels = prediction[0]['labels'].cpu().numpy()\n",
    "        det_threshold = 0.6\n",
    "        filtered_indices = scores >= det_threshold\n",
    "        filtered_labels = labels[filtered_indices]\n",
    "        object_names = [COCO_INSTANCE_CATEGORY_NAMES[label] for label in filtered_labels if 0 <= label < len(COCO_INSTANCE_CATEGORY_NAMES)]\n",
    "        if object_names:\n",
    "            prompt_text = \"Imagine an Image and Generate a detailed, descriptive sentence using these words in a natural context \" + \", \".join(object_names)\n",
    "            caption = text_generator(prompt_text, max_length=40)[0]['generated_text']\n",
    "        else:\n",
    "            caption = \"No objects detected, so no sentence was created.\"\n",
    "        results[os.path.basename(image_path)] = caption\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_pseudo_caption.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"Pseudo Caption Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
